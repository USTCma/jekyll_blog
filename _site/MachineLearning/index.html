
<!doctype html>














<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



  
  
    
    
  <script src="/assets/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/assets/lib/pace/pace-theme-bounce.min.css?v=1.0.2" rel="stylesheet">




  
  
  <link rel="stylesheet" media="all" href="/assets/lib/Han/dist/han.min.css?v=3.3">




<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="googleeb44c526f98c35f5.html" />













  
  
  <link href="/assets/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  

  

  

  

  

  






<link href="/assets/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/assets/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="代码,机器学习,算法," />





  <link rel="alternate" href="/atom.xml" title="细节 · 匠心" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/assets/images/favicon.ico?v=5.1.1" />
















<meta name="description" content="谷歌董事长施密特曾说过：虽然谷歌的无人驾驶汽车和机器人受到了许多媒体关注，但是这家公司真正的未来在于机器学习，一种让计算机更聪明、更个性化的技术。">
<meta name="keywords" content="代码, 机器学习, 算法">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习算法总结">
<meta property="og:url" content="http://localhost:4000/MachineLearning/">
<meta property="og:site_name" content="细节 · 匠心">
<meta property="og:description" content="谷歌董事长施密特曾说过：虽然谷歌的无人驾驶汽车和机器人受到了许多媒体关注，但是这家公司真正的未来在于机器学习，一种让计算机更聪明、更个性化的技术。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://oqsovnm36.bkt.clouddn.com/1.jpg">
<meta property="og:image" content="http://oqsovnm36.bkt.clouddn.com/2.jpg">
<meta property="og:image" content="http://oqsovnm36.bkt.clouddn.com/3.jpg">
<meta property="og:image" content="http://oqsovnm36.bkt.clouddn.com/4.jpg">
<meta property="og:image" content="http://oqsovnm36.bkt.clouddn.com/5.jpg">
<meta property="og:image" content="http://latex.codecogs.com/gif.latex?P(c|x)=\\frac{P(x|c)\\cdot P(c)}{P(x)}">
<meta property="og:image" content="http://oqsovnm36.bkt.clouddn.com/6.jpg">
<meta property="og:image" content="http://oqsovnm36.bkt.clouddn.com/7.jpg">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习算法总结">
<meta name="twitter:description" content="谷歌董事长施密特曾说过：虽然谷歌的无人驾驶汽车和机器人受到了许多媒体关注，但是这家公司真正的未来在于机器学习，一种让计算机更聪明、更个性化的技术。">
<meta name="twitter:image" content="http://oqsovnm36.bkt.clouddn.com/1.jpg">


<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":true},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '作者'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://localhost:4000/"/>





  <title>机器学习算法总结</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-69859995-1', 'auto');
  ga('send', 'pageview');
</script>







<script>
  	var _mtac = {};
  	(function() {
  		var mta = document.createElement("script");
  		mta.src = "https://pingjs.qq.com/h5/stats.js?v2.0.4";
  		mta.setAttribute("name", "MTAH5");
  		mta.setAttribute("sid", "500002057");

  		var s = document.getElementsByTagName("script")[0];
  		s.parentNode.insertBefore(mta, s);
  	})();
</script>







</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">细节 · 匠心</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">小马的独立博客</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            简介
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>

<!--<script src="https://echarts.baidu.com/dist/echarts.common.min.js"></script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    menuSettings: {
      zoom: "None"
    },
    showMathMenu: false,
    jax: ["input/TeX","output/CommonHTML"],
    extensions: ["tex2jax.js"],
    TeX: {
      extensions: ["AMSmath.js","AMSsymbols.js"],
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
      inlineMath: [["\\(", "\\)"]],
      displayMath: [["\\[", "\\]"]]
    }
  });
</script>

<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.1/MathJax.js"></script>
-->
 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

<div id="posts" class="posts-expand">
  
  

  

  
  
  

  <article class="post post-type- " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://localhost:4000/MachineLearning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Rui Ma">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/assets/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="细节 · 匠心">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
          
          
            机器学习算法总结
          
        </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-10-05T16:21:00+08:00">
                2016-10-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/category/#/%E4%BB%A3%E7%A0%81" itemprop="url" rel="index">
                    <span itemprop="name">代码</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <span class="post-meta-divider">|</span>
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计</span>
                
                <span title="字数统计">
                  1533
                </span>
              

              

              
            </div>
          

          
            
                <div class="post-description">
                    
                </div>
            
          

        </div>
      </header>
    

    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        <p>谷歌董事长施密特曾说过：虽然谷歌的无人驾驶汽车和机器人受到了许多媒体关注，但是这家公司真正的未来在于机器学习，一种让计算机更聪明、更个性化的技术。</p>

<h1 id="广义的三种机器学习算法">广义的三种机器学习算法</h1>

<h2 id="监督式学习">监督式学习</h2>

<p>工作机制：这个算法由一个目标变量或结果变量（或因变量）组成。这些变量由已知的一系列预示变量（自变量）预测而来。利用这一系列变量，我们生成一个将输入值映射到期望输出值的函数。这个训练过程会一直持续，直到模型在训练数据上获得期望的精确度。监督式学习的例子有：回归、决策树、随机森林、K – 近邻算法、逻辑回归等。</p>

<h2 id="非监督式学习">非监督式学习</h2>

<p>工作机制：在这个算法中，没有任何目标变量或结果变量要预测或估计。这个算法用在不同的组内聚类分析。这种分析方式被广泛地用来细分客户，根据干预的方式分为不同的用户组。非监督式学习的例子有：关联算法和 K – 均值算法。</p>

<h2 id="强化学习">强化学习</h2>

<p>工作机制：这个算法训练机器进行决策。它是这样工作的：机器被放在一个能让它通过反复试错来训练自己的环境中。机器从过去的经验中进行学习，并且尝试利用了解最透彻的知识作出精确的商业判断。 强化学习的例子有马尔可夫决策过程。</p>

<h1 id="常见机器学习算法名单">常见机器学习算法名单</h1>

<p>这里是一个常用的机器学习算法名单。这些算法几乎可以用在所有的数据问题上：</p>

<ol>
  <li>
    <p>线性回归</p>
  </li>
  <li>
    <p>逻辑回归</p>
  </li>
  <li>
    <p>决策树</p>
  </li>
  <li>
    <p>SVM</p>
  </li>
  <li>
    <p>朴素贝叶斯</p>
  </li>
  <li>
    <p>K最近邻算法</p>
  </li>
  <li>
    <p>K均值算法</p>
  </li>
  <li>
    <p>随机森林算法</p>
  </li>
  <li>
    <p>降维算法</p>
  </li>
  <li>
    <p>Gradient Boost 和 Adaboost 算法</p>
  </li>
</ol>

<h2 id="线性回归">线性回归</h2>

<p>线性回归通常用于根据连续变量估计实际数值（房价、呼叫次数、总销售额等）。我们通过拟合最佳直线来建立自变量和因变量的关系。这条最佳直线叫做回归线，并且用 Y=a*X+b 这条线性等式来表示。</p>

<p>理解线性回归的最好办法是回顾一下童年。假设在不问对方体重的情况下，让一个五年级的孩子按体重从轻到重的顺序对班上的同学排序，你觉得这个孩子会怎么做？他（她）很可能会目测人们的身高和体型，综合这些可见的参数来排列他们。这是现实生活中使用线性回归的例子。实际上，这个孩子发现了身高和体型与体重有一定的关系，这个关系看起来很像上面的等式。</p>

<p>在这个等式中：</p>

<ul>
  <li>
    <p>Y：因变量</p>
  </li>
  <li>
    <p>a：斜率</p>
  </li>
  <li>
    <p>x：自变量</p>
  </li>
  <li>
    <p>b ：截距</p>
  </li>
  <li>
    <p>系数 a 和 b 可以通过最小二乘法获得。</p>
  </li>
</ul>

<p>参见下例。我们找出最佳拟合直线 y=0.2811x+13.9。已知人的身高，我们可以通过这条等式求出体重。</p>

<p><img src="http://oqsovnm36.bkt.clouddn.com/1.jpg" alt="线性回归" /></p>

<p>线性回归的两种主要类型是一元线性回归和多元线性回归。一元线性回归的特点是只有一个自变量。多元线性回归的特点正如其名，存在多个自变量。找最佳拟合直线的时候，你可以拟合到多项或者曲线回归。这些就被叫做多项或曲线回归。</p>

<p><strong>Python 代码</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#Import Library</span>
<span class="c">#Import other necessary libraries like pandas, numpy...</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
 
<span class="c">#Load Train and Test datasets</span>
<span class="c">#Identify feature and response variable(s) and values must be numeric and numpy arrays</span>
<span class="n">x_train</span><span class="o">=</span><span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span><span class="o">=</span><span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span><span class="o">=</span><span class="n">input_variables_values_test_datasets</span>
 
<span class="c"># Create linear regression object</span>
<span class="n">linear</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>
 
<span class="c"># Train the model using the training sets and check score</span>
<span class="n">linear</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">linear</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
 
<span class="c">#Equation coefficient and Intercept</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Coefficient: n'</span><span class="p">,</span> <span class="n">linear</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Intercept: n'</span><span class="p">,</span> <span class="n">linear</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
 
<span class="c">#Predict Output</span>
<span class="n">predicted</span><span class="o">=</span> <span class="n">linear</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="逻辑回归">逻辑回归</h2>

<p>别被它的名字迷惑了！这是一个分类算法而不是一个回归算法。该算法可根据已知的一系列因变量估计离散数值（比方说二进制数值 0 或 1 ，是或否，真或假）。简单来说，它通过将数据拟合进一个逻辑函数来预估一个事件出现的概率。因此，它也被叫做逻辑回归。因为它预估的是概率，所以它的输出值大小在 0 和 1 之间（正如所预计的一样）。</p>

<p>让我们再次通过一个简单的例子来理解这个算法。</p>

<p>假设你的朋友让你解开一个谜题。这只会有两个结果：你解开了或是你没有解开。想象你要解答很多道题来找出你所擅长的主题。这个研究的结果就会像是这样：假设题目是一道十年级的三角函数题，你有 70%的可能会解开这道题。然而，若题目是个五年级的历史题，你只有30%的可能性回答正确。这就是逻辑回归能提供给你的信息。</p>

<p>从数学上看，在结果中，几率的对数使用的是预测变量的线性组合模型。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">odds</span><span class="o">=</span> <span class="n">p</span><span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span> <span class="o">=</span> <span class="n">probability</span> <span class="n">of</span> <span class="n">event</span> <span class="n">occurrence</span> <span class="o">/</span> <span class="n">probability</span> <span class="n">of</span> <span class="ow">not</span> <span class="n">event</span> <span class="n">occurrence</span>
<span class="n">ln</span><span class="p">(</span><span class="n">odds</span><span class="p">)</span> <span class="o">=</span> <span class="n">ln</span><span class="p">(</span><span class="n">p</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">))</span>
<span class="n">logit</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">=</span> <span class="n">ln</span><span class="p">(</span><span class="n">p</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">))</span> <span class="o">=</span> <span class="n">b0</span><span class="o">+</span><span class="n">b1X1</span><span class="o">+</span><span class="n">b2X2</span><span class="o">+</span><span class="n">b3X3</span><span class="o">....+</span><span class="n">bkXk</span>
</code></pre></div></div>

<p>在上面的式子里，p 是我们感兴趣的特征出现的概率。它选用使观察样本值的可能性最大化的值作为参数，而不是通过计算误差平方和的最小值（就如一般的回归分析用到的一样）。</p>

<p>现在你也许要问了，为什么我们要求出对数呢？简而言之，这种方法是复制一个阶梯函数的最佳方法之一。</p>

<p><img src="http://oqsovnm36.bkt.clouddn.com/2.jpg" alt="" /></p>

<p><strong>Python 代码</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#Import Library</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="c">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span>
<span class="c"># Create logistic regression object</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
 
<span class="c"># Train the model using the training sets and check score</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
 
<span class="c">#Equation coefficient and Intercept</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Coefficient: n'</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Intercept: n'</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
 
<span class="c">#Predict Output</span>
<span class="n">predicted</span><span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>更进一步：</strong></p>

<p>你可以尝试更多的方法来改进这个模型：</p>

<ul>
  <li>
    <p>加入交互项</p>
  </li>
  <li>
    <p>精简模型特性</p>
  </li>
  <li>
    <p>使用正则化方法</p>
  </li>
  <li>
    <p>使用非线性模型</p>
  </li>
</ul>

<h2 id="决策树">决策树</h2>

<p>这个监督式学习算法通常被用于分类问题。令人惊奇的是，它同时适用于分类变量和连续因变量。在这个算法中，我们将总体分成两个或更多的同类群。这是根据最重要的属性或者自变量来分成尽可能不同的组别。</p>

<p><img src="http://oqsovnm36.bkt.clouddn.com/3.jpg" alt="" /></p>

<p>在上图中你可以看到，根据多种属性，人群被分成了不同的四个小组，来判断 “他们会不会去玩”。为了把总体分成不同组别，需要用到许多技术，比如说 Gini、Information Gain、Chi-square、entropy。</p>

<p><strong>Python 代码</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#Import Library</span>
<span class="c">#Import other necessary libraries like pandas, numpy...</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
 
<span class="c">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span>
<span class="c"># Create tree object </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s">'gini'</span><span class="p">)</span> <span class="c"># for classification, here you can change the algorithm as gini or entropy (information gain) by default it is gini  </span>
 
<span class="c"># model = tree.DecisionTreeRegressor() for regression</span>
<span class="c"># Train the model using the training sets and check score</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
 
<span class="c">#Predict Output</span>
<span class="n">predicted</span><span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="支持向量机">支持向量机</h2>

<p>这是一种分类方法。在这个算法中，我们将每个数据在N维空间中用点标出（N是你所有的特征总数），每个特征的值是一个坐标的值。</p>

<p>举个例子，如果我们只有身高和头发长度两个特征，我们会在二维空间中标出这两个变量，每个点有两个坐标（这些坐标叫做支持向量）。</p>

<p><img src="http://oqsovnm36.bkt.clouddn.com/4.jpg" alt="" /></p>

<p>现在，我们会找到将两组不同数据分开的一条直线。两个分组中距离最近的两个点到这条线的距离同时最优化。</p>

<p><img src="http://oqsovnm36.bkt.clouddn.com/5.jpg" alt="" /></p>

<p>上面示例中的黑线将数据分类优化成两个小组，两组中距离最近的点（图中A、B点）到达黑线的距离满足最优条件。这条直线就是我们的分割线。接下来，测试数据落到直线的哪一边，我们就将它分到哪一类去。</p>

<p><strong>Python 代码</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#Import Library</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
 
<span class="c">#Assumed you have, X (predic</span>
<span class="n">tor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">Y</span> <span class="p">(</span><span class="n">target</span><span class="p">)</span> <span class="k">for</span> <span class="n">training</span> <span class="n">data</span> <span class="nb">set</span> <span class="ow">and</span> <span class="n">x_test</span><span class="p">(</span><span class="n">predictor</span><span class="p">)</span> <span class="n">of</span> <span class="n">test_dataset</span>
<span class="c"># Create SVM classification object </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">svc</span><span class="p">()</span> <span class="c"># there is various option associated with it, this is simple for classification. You can refer link, for mo# re detail.</span>
<span class="c"># Train the model using the training sets and check score</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
 
<span class="c">#Predict Output</span>
<span class="n">predicted</span><span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="朴素贝叶斯">朴素贝叶斯</h2>

<p>在预示变量间相互独立的前提下，根据贝叶斯定理可以得到朴素贝叶斯这个分类方法。用更简单的话来说，一个朴素贝叶斯分类器假设一个分类的特性与该分类的其它特性不相关。举个例子，如果一个水果又圆又红，并且直径大约是 3 英寸，那么这个水果可能会是苹果。即便这些特性互相依赖，或者依赖于别的特性的存在，朴素贝叶斯分类器还是会假设这些特性分别独立地暗示这个水果是个苹果。</p>

<p>朴素贝叶斯模型易于建造，且对于大型数据集非常有用。虽然简单，但是朴素贝叶斯的表现却超越了非常复杂的分类方法。</p>

<p>贝叶斯定理提供了一种从 P(c)、P(x) 和 P(x|c) 计算后验概率 P(c|x) 的方法。请看以下等式：</p>

<p><img src="http://latex.codecogs.com/gif.latex?P(c|x)=\frac{P(x|c)\cdot P(c)}{P(x)}" title="P(x|c)=\frac{P(c|x)\cdot P(x)}{P(x)}" /></p>

<p>在这里:</p>

<ul>
  <li>
    <p>P(c|x) 是已知预示变量（属性）的前提下，类（目标）的后验概率</p>
  </li>
  <li>
    <p>P(c) 是类的先验概率</p>
  </li>
  <li>
    <p>P(x|c) 是可能性，即已知类的前提下，预示变量的概率</p>
  </li>
  <li>
    <p>P(x) 是预示变量的先验概率</p>
  </li>
</ul>

<p>朴素贝叶斯使用了一个相似的方法，通过不同属性来预测不同类别的概率。这个算法通常被用于文本分类，以及涉及到多个类的问题。</p>

<p><strong>Python 代码</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#Import Library</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
 
<span class="c">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span>
<span class="c"># Create SVM classification object model = GaussianNB() # there is other distribution for multinomial classes like Bernoulli Naive Bayes, Refer link</span>
<span class="c"># Train the model using the training sets and check score</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
 
<span class="c">#Predict Output</span>
<span class="n">predicted</span><span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="knnk--最近邻算法">KNN（K – 最近邻算法）</h2>

<p>该算法可用于分类问题和回归问题。然而，在业界内，K – 最近邻算法更常用于分类问题。K – 最近邻算法是一个简单的算法。它储存所有的案例，通过周围k个案例中的大多数情况划分新的案例。根据一个距离函数，新案例会被分配到它的 K 个近邻中最普遍的类别中去。</p>

<p>这些距离函数可以是欧式距离、曼哈顿距离、明式距离或者是汉明距离。前三个距离函数用于连续函数，第四个函数（汉明函数）则被用于分类变量。如果 K=1，新案例就直接被分到离其最近的案例所属的类别中。有时候，使用 KNN 建模时，选择 K 的取值是一个挑战。</p>

<p><img src="http://oqsovnm36.bkt.clouddn.com/6.jpg" alt="" /></p>

<p>我们可以很容易地在现实生活中应用到 KNN。如果想要了解一个完全陌生的人，你也许想要去找他的好朋友们或者他的圈子来获得他的信息。</p>

<p>在选择使用 KNN 之前，你需要考虑的事情：</p>

<ul>
  <li>
    <p>KNN 的计算成本很高。</p>
  </li>
  <li>
    <p>变量应该先标准化（normalized），不然会被更高范围的变量偏倚。</p>
  </li>
  <li>
    <p>在使用KNN之前，要在野值去除和噪音去除等前期处理多花功夫。</p>
  </li>
</ul>

<p><strong>Python 代码</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#Import Library</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
 
<span class="c">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span>
<span class="c"># Create KNeighbors classifier object model </span>
<span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span> <span class="c"># default value for n_neighbors is 5</span>
 
<span class="c"># Train the model using the training sets and check score</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
 
<span class="c">#Predict Output</span>
<span class="n">predicted</span><span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="k均值算法">K均值算法</h2>

<p>K–均值算法是一种非监督式学习算法，它能解决聚类问题。使用 K – 均值算法来将一个数据归入一定数量的集群（假设有 k 个集群）的过程是简单的。一个集群内的数据点是均匀齐次的，并且异于别的集群。</p>

<p>还记得从墨水渍里找出形状的活动吗？K–均值算法在某方面类似于这个活动。观察形状，并延伸想象来找出到底有多少种集群或者总体。</p>

<p><strong>K – 均值算法怎样形成集群：</strong></p>

<ol>
  <li>
    <p>K–均值算法给每个集群选择k个点。这些点称作为质心。</p>
  </li>
  <li>
    <p>每一个数据点与距离最近的质心形成一个集群，也就是 k 个集群。</p>
  </li>
  <li>
    <p>根据现有的类别成员，找出每个类别的质心。现在我们有了新质心。</p>
  </li>
  <li>
    <p>当我们有新质心后，重复步骤 2 和步骤3。找到距离每个数据点最近的质心，并与新的k集群联系起来。重复这个过程，直到数据都收敛了，也就是当质心不再改变。</p>
  </li>
</ol>

<p><strong>如何决定 K 值：</strong></p>

<p>K–均值算法涉及到集群，每个集群有自己的质心。一个集群内的质心和各数据点之间距离的平方和形成了这个集群的平方值之和。同时，当所有集群的平方值之和加起来的时候，就组成了集群方案的平方值之和。</p>

<p>我们知道，当集群的数量增加时，K值会持续下降。但是，如果你将结果用图表来表示，你会看到距离的平方总和快速减少。到某个值 k 之后，减少的速度就大大下降了。在此，我们可以找到集群数量的最优值。</p>

<p><img src="http://oqsovnm36.bkt.clouddn.com/7.jpg" alt="" /></p>

<p><strong>Python 代码</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#Import Library</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
 
<span class="c">#Assumed you have, X (attributes) for training data set and x_test(attributes) of test_dataset</span>
<span class="c"># Create KNeighbors classifier object model </span>
<span class="n">k_means</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
 
<span class="c"># Train the model using the training sets and check score</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
 
<span class="c">#Predict Output</span>
<span class="n">predicted</span><span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="随机森林">随机森林</h2>

<p>随机森林是表示决策树总体的一个专有名词。在随机森林算法中，我们有一系列的决策树（因此又名“森林”）。为了根据一个新对象的属性将其分类，每一个决策树有一个分类，称之为这个决策树“投票”给该分类。这个森林选择获得森林里（在所有树中）获得票数最多的分类。</p>

<p>每棵树是像这样种植养成的：</p>

<p>如果训练集的案例数是 N，则从 N 个案例中用重置抽样法随机抽取样本。这个样本将作为“养育”树的训练集。</p>

<p>假如有 M 个输入变量，则定义一个数字 m«M。m 表示，从 M 中随机选中 m 个变量，这 m 个变量中最好的切分会被用来切分该节点。在种植森林的过程中，m 的值保持不变。</p>

<p>尽可能大地种植每一棵树，全程不剪枝。</p>

<p>若想了解这个算法的更多细节，比较决策树以及优化模型参数，我建议你阅读以下文章：</p>

<ol>
  <li>
    <p><a href="http://www.analyticsvidhya.com/blog/2014/06/introduction-random-forest-simplified/">随机森林入门—简化版</a></p>
  </li>
  <li>
    <p><a href="http://www.analyticsvidhya.com/blog/2014/06/comparing-cart-random-forest-1/">将 CART 模型与随机森林比较（上）</a></p>
  </li>
  <li>
    <p><a href="http://www.analyticsvidhya.com/blog/2014/06/comparing-random-forest-simple-cart-model/">将随机森林与 CART 模型比较（下）</a></p>
  </li>
  <li>
    <p><a href="http://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/">调整你的随机森林模型参数</a></p>
  </li>
</ol>

<p><strong>Python 代码</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#Import Library</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
 
<span class="c">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span>
<span class="c"># Create Random Forest object</span>
<span class="n">model</span><span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
 
<span class="c"># Train the model using the training sets and check score</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
 
<span class="c">#Predict Output</span>
<span class="n">predicted</span><span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="降维算法">降维算法</h2>

<p>在过去的 4 到 5 年里，在每一个可能的阶段，信息捕捉都呈指数增长。公司、政府机构、研究组织在应对着新资源以外，还捕捉详尽的信息。</p>

<p>举个例子：电子商务公司更详细地捕捉关于顾客的资料：个人信息、网络浏览记录、他们的喜恶、购买记录、反馈以及别的许多信息，比你身边的杂货店售货员更加关注你。</p>

<p>作为一个数据科学家，我们提供的数据包含许多特点。这听起来给建立一个经得起考研的模型提供了很好材料，但有一个挑战：如何从 1000 或者 2000 里分辨出最重要的变量呢？在这种情况下，降维算法和别的一些算法（比如决策树、随机森林、PCA、因子分析）帮助我们根据相关矩阵，缺失的值的比例和别的要素来找出这些重要变量。</p>

<p>想要知道更多关于该算法的信息，可以阅读<a href="http://www.analyticsvidhya.com/blog/2015/07/dimension-reduction-methods/">《降维算法的初学者指南》</a>。</p>

<p><strong>Python 代码</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#Import Library</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">decomposition</span>
 
<span class="c">#Assumed you have training and test data set as train and test</span>
<span class="c"># Create PCA obeject pca= decomposition.PCA(n_components=k) #default value of k =min(n_sample, n_features)</span>
<span class="c"># For Factor analysis</span>
<span class="c">#fa= decomposition.FactorAnalysis()</span>
<span class="c"># Reduced the dimension of training dataset using PCA</span>
<span class="n">train_reduced</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
 
<span class="c">#Reduced the dimension of test dataset</span>
<span class="n">test_reduced</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="gradient-boosting-和-adaboost-算法">Gradient Boosting 和 AdaBoost 算法</h2>

<p>当我们要处理很多数据来做一个有高预测能力的预测时，我们会用到 GBM 和 AdaBoost 这两种 boosting 算法。boosting 算法是一种集成学习算法。它结合了建立在多个基础估计值基础上的预测结果，来增进单个估计值的可靠程度。这些 boosting 算法通常在数据科学比赛如 Kaggl、AV Hackathon、CrowdAnalytix 中很有效。</p>

<p><a href="http://www.analyticsvidhya.com/blog/2015/05/boosting-algorithms-simplified/">更多关于 Gradient 和 AdaBoost</a></p>

<p><strong>Python 代码</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#Import Library</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
 
<span class="c">#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset</span>
<span class="c"># Create Gradient Boosting Classifier object</span>
<span class="n">model</span><span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
 
<span class="c"># Train the model using the training sets and check score</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
 
<span class="c">#Predict Output</span>
<span class="n">predicted</span><span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</code></pre></div></div>

<p>GradientBoostingClassifier 和随机森林是两种不同的 boosting 树分类器。</p>

      
    </div>

    <div>
      
        
<div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
    <img id="wechat_subscriber_qcode" src="http://oqsovnm36.bkt.clouddn.com/qrcode.jpg" alt="Rui Ma wechat" style="width: 200px; max-width: 100%;"/>
    <div>关注公众号</div>
</div>


      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div></div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="http://oqsovnm36.bkt.clouddn.com/wechatpay.jpg" alt="Rui Ma WeChat Pay"/>
          <p style="text-align: center;">微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="http://oqsovnm36.bkt.clouddn.com/alipay.jpg" alt="Rui Ma Alipay"/>
          <p style="text-align: center;">支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <div>
      
        
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong>本文作者：</strong>
      Rui Ma
    </li>
    <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://localhost:4000/MachineLearning/" title="机器学习算法总结">http://localhost:4000/MachineLearning/</a>
    </li>
    <li class="post-copyright-license">
      <strong>版权声明： </strong>
      本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
    </li>
  </ul>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            
            <a href="/tag/#/%E4%BB%A3%E7%A0%81" rel="tag"><i class="menu-item-icon fa fa-fw fa-tags"></i> 代码</a>
          
            
            <a href="/tag/#/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0" rel="tag"><i class="menu-item-icon fa fa-fw fa-tags"></i> 机器学习</a>
          
            
            <a href="/tag/#/%E7%AE%97%E6%B3%95" rel="tag"><i class="menu-item-icon fa fa-fw fa-tags"></i> 算法</a>
          
        </div>
      

      
      
      
      
      

      
      
        <div class="post-nav" id="post-nav-id">
          <div class="post-nav-next post-nav-item">
            
              <a href="/VPS/" rel="next" title="VPS上的l2tp和pptp搭建">
                <i class="fa fa-chevron-left"></i> VPS上的l2tp和pptp搭建
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/ColdBoot/" rel="prev" title="冷启动总结">
                冷启动总结 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      
      

      
    </footer>
  </article>

  <div class="post-spread">
    
      
  <script>
    window._bd_share_config = {
      "common": {
        "bdText": "",
        "bdMini": "1",
        "bdMiniList": false,
        "bdPic": ""
      },
      "image": {
        "viewList": ["tsina", "douban", "sqq", "qzone", "weixin", "twi", "fbook"],
        "viewText": "分享到：",
        "viewSize": "16"
      },
      "slide": {
        "bdImg": "5",
        "bdPos": "left",
        "bdTop": "100"
      }
    }
  </script>

<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

    
  </div>
</div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="gitmentContainer"></div>
      <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
      <script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
      <script>
        var gitment = new Gitment({
          owner: 'ustcma',
          repo: 'ustcma.github.io',
          oauth: {
            client_id: 'f3cb4aadea6927192afc4918acabf9c5e17d8d54',
            client_secret: 'c1fe481abf2adf4cffbe',
          },
        });
        gitment.render('gitmentContainer');
      </script>
    
  </div>


        </div>
        
          

  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      
        
        
        




      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/assets/images/avatar.png"
               alt="Rui Ma" />
          <p class="site-author-name" itemprop="name">Rui Ma</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">29</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/">
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/">
                <span class="site-state-item-count">45</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
        
        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              
              
              <span class="links-of-author-item">
                <a href="mailto:ustcmrui@gmail.com" target="_blank" title="E-Mail">
                  
                    <i class="fa fa-fw fa-envelope"></i>
                  
                  E-Mail
                </a>
              </span>
            
              
              
              <span class="links-of-author-item">
                <a href="https://twitter.com/i_marui" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
              
              
              <span class="links-of-author-item">
                <a href="http://weibo.com/rui110" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
              
              
              <span class="links-of-author-item">
                <a href="https://www.instagram.com/ruima110" target="_blank" title="Instagram">
                  
                    <i class="fa fa-fw fa-instagram"></i>
                  
                  Instagram
                </a>
              </span>
            
              
              
              <span class="links-of-author-item">
                <a href="https://www.facebook.com/ruima110" target="_blank" title="Facebook">
                  
                    <i class="fa fa-fw fa-facebook"></i>
                  
                  Facebook
                </a>
              </span>
            
          
        </div>

        
        

        
        

        <div id="music163player">
    <iframe frameborder="Yes" border="0" marginwidth="0" marginheight="0" width=280 height=86 src="//music.163.com/outchain/player?type=2&id=33761576&auto=0&height=66">
    </iframe>
</div>


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            





            
              <div class="post-toc-content">
    <ol class=nav>
      <li class="nav-item nav-level-1"> <a class="nav-link" href="#广义的三种机器学习算法"> <span class="nav-number">1</span> <span class="nav-text">广义的三种机器学习算法</span> </a> <ol class="nav-child"> <li class="nav-item nav-level-2"> <a class="nav-link" href="#监督式学习"> <span class="nav-number">1.1</span> <span class="nav-text">监督式学习</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#非监督式学习"> <span class="nav-number">1.2</span> <span class="nav-text">非监督式学习</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#强化学习"> <span class="nav-number">1.3</span> <span class="nav-text">强化学习</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-1"> <a class="nav-link" href="#常见机器学习算法名单"> <span class="nav-number">2</span> <span class="nav-text">常见机器学习算法名单</span> </a> <ol class="nav-child"> <li class="nav-item nav-level-2"> <a class="nav-link" href="#线性回归"> <span class="nav-number">2.1</span> <span class="nav-text">线性回归</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#逻辑回归"> <span class="nav-number">2.2</span> <span class="nav-text">逻辑回归</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#决策树"> <span class="nav-number">2.3</span> <span class="nav-text">决策树</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#支持向量机"> <span class="nav-number">2.4</span> <span class="nav-text">支持向量机</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#朴素贝叶斯"> <span class="nav-number">2.5</span> <span class="nav-text">朴素贝叶斯</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#knnk--最近邻算法"> <span class="nav-number">2.6</span> <span class="nav-text">KNN（K – 最近邻算法）</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#k均值算法"> <span class="nav-number">2.7</span> <span class="nav-text">K均值算法</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#随机森林"> <span class="nav-number">2.8</span> <span class="nav-text">随机森林</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#降维算法"> <span class="nav-number">2.9</span> <span class="nav-text">降维算法</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#gradient-boosting-和-adaboost-算法"> <span class="nav-number">2.10</span> <span class="nav-text">Gradient Boosting 和 AdaBoost 算法</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child">
    </ol>
  </div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>

        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" style="text-align:center">
  Copyright 
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="author" itemprop="copyrightHolder">Rui Ma</span>
</div>

        
<div class="busuanzi-count" style="text-align:center">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      本站访客数量：
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      本站总访问量：
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>





















  
   
  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/jquery/index.js?v=2.1.3"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/assets/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/assets/js/src/motion.js?v=5.1.1"></script>



  
  

  <script type="text/javascript" src="/assets/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/assets/js/src/post-details.js?v=5.1.1"></script>


  


  <script type="text/javascript" src="/assets/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  




  

    

  





  


  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('-1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  


  
  


  

  
  <script type="text/javascript" src="/assets/js/src/exturl.js?v=5.1.1"></script>


</body>
</html>

